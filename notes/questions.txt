> we are sending our train and test data to the feature store separetely, should we do this

> we've seen that whenever we create a new pipeline using the kedro CLI a new parameter file is also created, e.g. parameters_model_selection.yml, how to call these files in the pipelines?

> how would the pipelines change if we were using models not just from sklearn? ans: by wrapping models in base estimators and classifier mixin:
e.g.
from sklearn.base import BaseEstimator, ClassifierMixin
import xgboost as xgb
import numpy as np

class XGBoostWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, **kwargs):
        self.params = kwargs
        self.model = None

    def fit(self, X, y):
        dtrain = xgb.DMatrix(X, label=y)
        self.model = xgb.train(self.params, dtrain)
        return self

    def predict(self, X):
        dtest = xgb.DMatrix(X)
        return np.round(self.model.predict(dtest))

    def predict_proba(self, X):
        dtest = xgb.DMatrix(X)
        return self.model.predict(dtest)
